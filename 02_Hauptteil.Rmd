## Die Forschungsfrage

-   Darstellung der FF
-   Überblick über Literatur, vor allem Jones als Ausgangspaper

Jones (2007) unterteilt in ihrem Paper "Examination of fund age and size and its impact on hedge fund performance" die untersuchten Hedgefunds in drei Größenkategorien auf. Größe, englisch "size" definiert sich nach Stafylas (2016) als Assets under Management (AUM). Jones unterscheidet zwischen Funds kleiner 100 Millionen USD, 100 bis 500M USD und Funds größer als 500M USD. Im Anschluss wird eine Performance-Analyse mittels des mon. returns der letzen zehn Jahre durchgeführt. Hierbei stellt Jones (2007) zwar höhere returns für kleine Funds fest, diese gehen aber auch mit einer höheren Volatilität einher. So ergibt als ..., während die Volatilität....

Jones (2007) untersucht im Anschluss Performance-Unterschiede für Hedgefunds unterschiedlichen Alters. Auch hier werden drei Kategorien je nach Alter der Funds definiert, jünger als zwei Jahre, zwei bis vier Jahre und älter als vier Jahre. Bei der Analyse der returns stellt Jones (2007) einen Vorteil von jungen gegenüber etablierten, älteren Funds fest.

Frumkin (2009): - Alter spielt eine Rolle, Größe nicht - Gleicher Zshg. von Alter/performance wie bei Jones (2007)

### Einfluss von Alter und Größe auf Performance

### Motivation hinter Forschungsfrage

\newpage

## Datensatz

-   Darstellung des Datensatzes, hier mit ersten einfachen R-Operationen (summary und so)
-   Wie haben wir die Hedgefunds ausgewählt?

### Darstellung der verwendeten Daten

Zuerst müssen die Daten aus dem datensatz "Basedata" geladen und die benötigten Variablen ausgesucht werden.

```{r, echo=FALSE}
#laden der benötigten packages
library(tidyverse)
library(scales)
library(lubridate)
library(RColorBrewer)
```

```{r, echo=FALSE}
#Laden von Basedata, Auswahl der verwendeten Variablen
basedata <- read_csv("DATA/basedata.csv")


basedata <- select(basedata, name, secid, `Inception Date`,`Obsolete Date`, `Fund Size Date`, `Fund Size USD`, `Net Assets Date`,`Net Assets - Share Class USD`)

```

Im Anschluss wird ein Zeitintervall für die Analyse bestimmt. In der vorliegenden Analyse werden nur Funds, die vor 20.. gegründet und bis einschließlich 20.. aktiv waren, untersucht. Für einige Funds wird kein Obsolete Date aufgeführt. Da aber häufig Ablesedaten für die size aufgeführt werden, wird für alle NAs das Ablesedatum der Größe eingefügt. Liegt dieses ebenfalls nicht vor, werden diese Funds nicht berücksichtigt.

```{r, echo=FALSE}
#Ersetzen der NAs für spätestes Ablesedatum und Auswahl der Funds jünger als 2005-01-01 und aktiv bis 2015

age_final <- basedata %>%
  mutate(`Obsolete Date` = coalesce(`Obsolete Date`,`Fund Size Date`))%>%
  filter(`Inception Date`< "2005-01-01")%>%
  filter(`Obsolete Date`> "2015-01-01")


```

Um Altersvergleiche zu bestimmen, müssen das Alter bzw. die Lebensspanne der funds bestimmt werden.Als Alter wird das Alter zum Beginn des Intervalls verwendet.

```{r, echo=FALSE}

#Alter als Differenz von der unteren Grenze 2015-01-01, Umwandlung in Jahre gerundet als neue Spalte

age_final <- age_final %>%
  mutate(Age_Int=as.Date("2005-01-01"))%>%
  mutate(Age= (`Age_Int` - `Inception Date`))%>%
  mutate((Month = round((Age/30.417)/12, digit=1)))%>%
  mutate(Age_Years=as.numeric(`(Month = round((Age/30.417)/12, digit = 1))`))%>%
  select(name, secid,`Inception Date`,`Obsolete Date`,Age_Years)
```

```{r, echo=FALSE}
# Bildung der Klassen für das Alter

age_final <- age_final%>%
  mutate(Class = case_when(
Age_Years < 2  ~ "young", Age_Years >= 2 & Age_Years < 4 ~ "medium", Age_Years >= 4 ~ "old"))%>%
  arrange(secid, .by_group = FALSE)

ggplot(age_final)+ geom_bar(aes(Class))+ theme_minimal()
```

Um Größenvergleiche durchzuführen,werden aus dem Set alle Funds ohne einen Wert für size gelöscht. [Im Anschluss wird ebenfalls das Interval 2005 bis 2015 gebildet. Als Stichprobe ergeben sich 89 aktive Funds]

```{r, echo=FALSE}
#Für Größenvergleich Löschen aller Funds ohne Fund Size value oder Net Asset Value

basedata_size <- filter(basedata, `Net Assets - Share Class USD`>0 | `Fund Size USD` >0 )

#auch hier anlegen der Daten, filtern nach Zeitinterval 2010 bis 2020, dann Auswahl der Funds, die mindestens fünf Jahre in Interval aktiv

size_final <- basedata_size %>% 
    mutate(`Obsolete Date` = coalesce(`Obsolete Date`,`Fund Size Date`))%>%
  filter(`Fund Size Date`>="2010-01-01" | `Net Assets Date`>= "2010-01-01")%>%
  filter(`Obsolete Date`>= "2015-01-01")

#Klassenbildung für Größe

size_final <- size_final%>%
  mutate(`Fund Size USD` = coalesce(`Fund Size USD`, `Net Assets - Share Class USD`))%>%
  mutate(Class = case_when(`Fund Size USD`
 <= 100000000 ~ "small", `Fund Size USD` > 100000000  & `Fund Size USD` <= 500000000 ~ "medium", `Fund Size USD` > 500000000 ~ "big"))%>%
  arrange(secid, .by_group = FALSE)%>%
  select(name, secid,`Fund Size USD`, `Net Assets - Share Class USD`, Class)

ggplot(size_final)+ geom_bar(aes(Class))+ theme_minimal()

```

Im Anschluss wurden die weiteren Datensätze eingearbeitet und benannt. Zuerst der mri für den Zeitraum 2005-2015 zur Analyse des Alters und für 2010-2020 für die Größe.

```{r,echo=FALSE}
#laden des Datensatzes "mri"
mri <- read_csv("DATA/mri.csv")

# date-variable als date bezeichnen, format dem in age/size_final angleichen
mri$date <- as.Date(mri$date, format="%d.%m.%Y")
```




```{r}
#filtern nach Zeitinterval 2005-2015, behalten werden alle funds länger gleich als 60 Monate gelaufen


mri05_15 <- mri%>%
  filter(date>= "2005-01-01")%>%
  filter(date< "2015-01-01")%>%
  keep(~ (sum(. >= 0) / length(.)) >= 0.5)

#umwandeln aller funds in character, dann pivot_longer um daten zu reorganisieren
mri05_15$FHUSA04GGS <- as.character(mri05_15$FHUSA04GGS)
mri05_15$FHUSA04B6U <- as.character(mri05_15$FHUSA04B6U)
mri05_15$F00000GUU3 <- as.character(mri05_15$F00000GUU3)

tidy_data <- pivot_longer(mri05_15, cols = 2:715, names_to ="secid", values_to = "mri")

#mri von character in numeric
tidy_data$mri <- as.numeric(tidy_data$mri)
```

```{r}
#filtern nach Zeitinterval 2010-2020
mri10_20 <- mri%>%
  filter(date>= "2010-01-01")%>%
  filter(date< "2020-01-01")%>%
  keep(~ (sum(. >= 0) / length(.)) >= 0.5)
  

#Umwandeln aller funds in character
mri10_20$FHUSA04GGS <- as.character(mri10_20$FHUSA04GGS)
mri10_20$FHUSA04B6U <- as.character(mri10_20$FHUSA04B6U)
mri10_20$F00000GUU3 <- as.character(mri10_20$F00000GUU3)

#pivot longer
tidy_data_s <- pivot_longer(mri10_20, cols = 2:334, names_to ="secid", values_to = "mri")



#mri von character in numeric
tidy_data_s$mri <- as.numeric(tidy_data_s$mri)
```


Als nächstes werden die factordata bearbeitet

```{r,echo=FALSE}

#einlesen der daten
factordata <- read_csv("DATA/factordata.csv")

# date-variable als date bezeichnen, format dem in clean_final angleichen
factordata$date <- as.Date(factordata$date, format="%d.%m.%Y")

#filtern nach Zeitintervallen
factordata05_15 <- factordata%>%
  filter(date>= "2005-01-01")%>%
  filter(date< "2015-01-01")

factordata10_20 <- factordata%>%
  filter(date>= "2010-01-01")%>%
  filter(date< "2020-01-01")




```
\newpage

## Beschreibende Statistiken

-   Lagemaße, Streuung etc.
-   Erstes vorsichtiges Fazit

## Performance Measures

Nun können Verschiedene Kennziffern erstellt werden. 


1. Arithmetische Rendite (arithmetic return):

- Bekanntester Schätzer für erwartete Renditen
- Entspricht der durchschnittlichen Rendite pro Intervall (Monate, Jahre)

\begin{equation} 
  \label{Arithmetic_Return}
  \overline{r} = \frac{1}{T} \sum_{t = 1}^{T}r_t
\end{equation}


2. Volatilität (volatility):

- Meist genutztes Maß für idiosyncratisches Risiko

\begin{equation} 
  \label{Volatility}
  \sigma = \sqrt{\frac{1}{T - 1} \sum_{t = 1}^{T}(r_t - \overline{r}_t)^2}
\end{equation}

3. High Water Mark (HWM):

- Entspricht der Spitze der Historie der kumulierten Renditen

\begin{equation}
  \label{High_Water_Mark}
  HWM_t = max_{s \leq t}P_s
\end{equation}

4. Value-at-Risk (VaR):

- Entspricht dem Verlust, der mit einer bestimmten WSK nicht überschritten wird

\begin{equation}
  \label{Value_at_Risk}
  VaR_\alpha(X) = -inf\{X \in \mathbb{R} : F_x(x) \geq \alpha\}
\end{equation}

5. Drawdown (DD):

- Entspricht dem kumulierten Verlust, seitdem die Verlust-Phase begonnen hat

\begin{equation}
  \label{Drawdown}
  DD_t = \frac{HWM_t - P_t}{HWM_t}
\end{equation}


6. Maximum Drawdown (MDD):

- Wird genutzt, wenn ein bestimmter Zeit-Intervall untersucht wird

\begin{equation}
  \label{Maximum_Drawdown}
  MDD_T = max_{t \leq T}DD_t
\end{equation}


\\
Dies wird erst für die Grundgesamtheit der Funds aus der Periode 2005-2015 durchgeführt.

```{r,echo=FALSE}
#return,HWM und DD für mri für die einzelnen funds mit age

tidy_data <- tidy_data %>% 
  group_by(secid) %>% 
  mutate(lag_mri = lag(mri, n = 1), return = (mri-lag_mri)/lag_mri*100, hwm = cummax(mri), dd = (hwm - mri)/hwm)%>%
  ungroup() %>% 
  arrange(secid, date) %>%
  select(!lag_mri)


#mean return, volatility,VaR, maxDD für gesamte Stichprobe

summary_all <- tidy_data %>% 
  summarise(Mean = 12*mean(return, na.rm = TRUE), Volatility = sqrt(12)*sd(return, na.rm = TRUE), VaR = quantile(return, probs = 0.05, na.rm = TRUE),
MDD = max(dd, na.rm = TRUE))

```

Hier erste Interpretation \\


Im Anschluss werden die gleichen Kennziffern für die drei Klassen für Alter bestimmt.


```{r,echo=FALSE}
#mean return, volatility,VaR, maxDD für die funds bei Alter

summary <- tidy_data %>% 
  group_by(secid) %>% 
  summarise(Mean = 12*mean(return, na.rm = TRUE), Volatility = sqrt(12)*sd(return, na.rm = TRUE), VaR = quantile(return, probs = 0.05, na.rm = TRUE),
MDD = max(dd, na.rm = TRUE))%>%
  arrange(secid, .by_group = FALSE)

#erstellen eines großen Datensets mit Klassen von klein,mittel, groß
age_final_summary <- merge(age_final, summary, by = "secid")%>%
  arrange(secid, .by_group = FALSE)%>%
  select(secid, Class, Mean, Volatility, VaR, MDD )

ggplot(age_final_summary)+geom_bar(aes(x=Class), fill="steelblue")+theme_minimal()

#Erstellen der einzelnen Zusammenfassungen für die Klassen
summary_young <- age_final_summary%>%
  filter(Class=="young")%>%
  summarise(Mean = mean(Mean), Volatility = mean(Volatility), VaR = mean(VaR),
MDD = mean(MDD))%>%
  mutate(Class="young")%>%
  relocate(Class, .before = Mean)

summary_medium <- age_final_summary%>%
  filter(Class=="medium")%>%
  summarise(Mean = mean(Mean), Volatility = mean(Volatility), VaR = mean(VaR),
MDD = mean(MDD))%>%
  mutate(Class="medium")%>%
  relocate(Class, .before = Mean)


summary_old <- age_final_summary%>%
  filter(Class=="old")%>%
  summarise(Mean = mean(Mean), Volatility = mean(Volatility), VaR = mean(VaR),
MDD = mean(MDD))%>%
  mutate(Class="old")%>%
  relocate(Class, .before = Mean)

#Zusammenfassen in einer summary

summary_final <- bind_rows(summary_young,summary_medium,summary_old, .id = "Class")%>%
  mutate(Class= c("young","medium","old"))
```

Jetzt für Size das Gleiche 

```{r}

#lag erstellen, dann return, hwm, dd bestimmen
tidy_data_s <- tidy_data_s %>% 
  group_by(secid) %>% 
  mutate(lag_mri = lag(mri, n = 1), return = (mri-lag_mri)/lag_mri*100, hwm = cummax(mri), dd = (hwm - mri)/hwm)%>%
  ungroup() %>% 
  arrange(secid, date) %>%
  select(!lag_mri)


#mean return, volatility,VaR, maxDD für gesamte Stichprobe

summary_all_s <- tidy_data_s %>% 
  summarise(Mean = mean(return, na.rm = TRUE), Volatility = sd(return, na.rm = TRUE), VaR = quantile(return, probs = 0.05, na.rm = TRUE),
MDD = max(dd, na.rm = TRUE))
```

Und dann einzeln nochmal
```{r}
#mean return, volatility,VaR, maxDD für die funds

summary_s <- tidy_data_s %>% 
  group_by(secid) %>% 
  summarise(Mean = mean(return, na.rm = TRUE), Volatility = sd(return, na.rm = TRUE), VaR = quantile(return, probs = 0.05, na.rm = TRUE),
MDD = max(dd, na.rm = TRUE))%>%
  arrange(secid, .by_group = FALSE)

#Luca: hier bei fünf funds ein problem, das muss angeguckt werden


#erstellen eines großen Datensets mit Klassen von klein,mittel, groß
size_final_summary <- merge(size_final, summary_s, by = "secid")%>%
  arrange(secid, .by_group = FALSE)%>%
  select(secid, Class, Mean, Volatility, VaR, MDD )

ggplot(size_final_summary)+geom_bar(aes(x=Class), fill="steelblue")+theme_minimal()

#Erstellen der einzelnen Zusammenfassungen für die Klassen
summary_small <- size_final_summary%>%
  filter(Class=="small")%>%
  summarise(Mean = mean(Mean), Volatility = mean(Volatility), VaR = mean(VaR),
MDD = mean(MDD))%>%
  mutate(Class="small")%>%
  relocate(Class, .before = Mean)

summary_medium_s <- size_final_summary%>%
  filter(Class=="medium")%>%
  summarise(Mean = mean(Mean), Volatility = mean(Volatility), VaR = mean(VaR),
MDD = mean(MDD))%>%
  mutate(Class="medium")%>%
  relocate(Class, .before = Mean)


summary_big <- size_final_summary%>%
  filter(Class=="big")%>%
  summarise(Mean = mean(Mean), Volatility = mean(Volatility), VaR = mean(VaR),
MDD = mean(MDD))%>%
  mutate(Class="big")%>%
  relocate(Class, .before = Mean)

#Zusammenfassen in einer summary

summary_final_s <- bind_rows(summary_small,summary_medium_s,summary_big, .id = "Class")%>%
  mutate(Class= c("young","medium","old"))


```


\newpage

### Visualisierungen

Nach der Erstelllung der einzelnen beschreibenden Performance-Measures können diese Zusammenhänge auch visuell dargestellt werden.
Eine einfache Darstellung der returns ist nicht hilfreich, erst nach Klassifizierung und Bearbeitung der Daten ergeben sich die Zusammenhänge.

```{r,echo=FALSE}
#zum Spass: kleine darstellung für alle Funds, white noise

ggplot(data=tidy_data) + aes(x=date, y = return) +
geom_line()
```



```{r,echo=FALSE}
#Darstellung Zshg. Volatility/Mean für Alter
ggplot(data=summary_final) + geom_point(aes(x=Volatility, y = Mean, color = Class)) + theme_minimal()
```

\newpage

### Weitere Performance Maße

1.  Bruttorendite (gross return):

\begin{equation} 
  \label{Gross_Return}
  R_t = 1 + r_t = \frac{P_t}{P_{t-1}}
\end{equation}


2. Nettorendite (net return):

\begin{equation} 
  \label{Net_Return}
  r_t = \frac{P_t - P_{t-1}}{P_{t-1}} = \frac{P_t}{P_{t-1}}-1
\end{equation}


3. Überschussrendite:

- Nettorendite abzgl. der Referenzrendite, bspw. der risk-free interest rate
- Notwendig um $\alpha$ in Faktor-Modellen zu berechnen

\begin{equation} 
  \label{Excess_Return}
  r_t^e = r_t - r_{f,t}
\end{equation}

4. Expected Shortfall (ES):

- Entspricht dem arithmetischen Mittel derjenigen Returns, welche unter die VaR-Schwelle fallen

\begin{equation}
  \label{Expected_Shortfall}
  ES = E(X|X < VaR)
\end{equation}


\newpage


### Risiko-Management

LucaS: Wirklich nötig? Nicht VaR einfach oben drin?

### Alpha und Sharp-Ratio

Pi: gehört eigtl auch zu Performance Measures

1. Jensen's alpha
- Entspricht der marktneutralen Komponente der Rendite
- CAPM-Regression:

\begin{equation} 
  \label{CAPM_Regression}
  r_t^e = \alpha + \beta r_{M,t}^e + \epsilon_t
\end{equation}

- Durch Umstellung ergibt sich:

\begin{equation} 
  \label{Jensen's_Alpha}
  E(r_t^e - \beta r_{M,t}^e) = \alpha
\end{equation}

2. Carhart's alpha

- Die Regressionsgleichung wird um bekannte Faktoren ergänzt
- Die Faktoren sind:
  - Size factor: Small-minus-Big (SMB)
  - Value factor: High-minus-Low (HML)
  - Momentum factor: Up-minus-down (UMD)
  
\begin{equation} 
  \label{Carhart's_Alpha}
  r_t^e = \alpha + \beta * r_{M,t}^e + s * r_{SMB,t} + h * r_{HML,t} + m * r_{UMD,t} + \epsilon_t
\end{equation}


3.  Sharpe Ratio:

-   Die erwartete Überschussrendite in Relation zur Volatilität
-   Weniger anfällig für Leverage

\begin{equation} 
  \label{Sharpe_Ratio}
  SR = \frac{E(r - r_f)}{\sigma(r - r_f)} := \frac{\overline{r}^e}{\sigma(r^e)}
\end{equation}


4. Information Ratio:

- Das $\alpha$ in Relation zum idiosyncratischen Risiko des Hedge Funds

\begin{equation}
  \label{Information_Ratio_1}
  IR = \frac{\alpha}{\sigma(\epsilon)}
\end{equation}

- Sofern der Hedge Fund eine bestimmte Benchmark schlagen soll, kann die IR auch folgendermaßen beschrieben werden:

\begin{equation}
  \label{Information_Ratio_2}
  IR = \frac{E(r - r_b)}{\sigma(r - r_b)}
\end{equation}



### CAPM

1. Das CAPM-$\beta$:

- Maß für das systematische Risiko

\begin{equation} 
  \label{CAPM_Beta}
  \beta_i = \frac{Cov(r_i, r_M)}{\sigma(r_M)^2}
\end{equation}

### Regressionsmodell

### Tests

\newpage
